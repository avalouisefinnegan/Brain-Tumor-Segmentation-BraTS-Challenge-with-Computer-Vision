{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "# Pytorch functions\n",
    "import torch\n",
    "# Neural network layers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# Torchvision library\n",
    "from torchvision import transforms\n",
    "# Handling dataset\n",
    "import torch.utils.data as data\n",
    "\n",
    "# For results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed, use_cuda = True, use_mps = False):\n",
    "    \"\"\"\n",
    "    Set SEED for PyTorch reproducibility\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    if use_mps:\n",
    "        torch.mps.manual_seed(seed)\n",
    "\n",
    "SEED = 44\n",
    "\n",
    "USE_SEED = True\n",
    "\n",
    "if USE_SEED:\n",
    "    set_seed(SEED, torch.cuda.is_available(), torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crop(object):\n",
    "    def __init__(self, output_ind):\n",
    "        self.output_ind = output_ind\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample\n",
    "        new_image = []\n",
    "        output_ind = self.output_ind\n",
    "        for i in range(len(image)): # 4\n",
    "            new_image.append(image[i][output_ind[0][0]:output_ind[0][1], output_ind[1][0]:output_ind[1][1],:])\n",
    "            new_label = label[output_ind[0][0]:output_ind[0][1], output_ind[1][0]:output_ind[1][1],:]\n",
    "        return new_image, new_label\n",
    "\n",
    "class Flatten(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample # images have 4 image\n",
    "        new_image = []\n",
    "        for i in range(len(image)):\n",
    "            new_image.append(image[i].reshape(180, -1, order = 'F'))\n",
    "        new_label = label.reshape(-1)\n",
    "        return new_image, new_label\n",
    "    \n",
    "class ScanNormalize(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample\n",
    "        new_image = []\n",
    "        for i in range(len(image)):\n",
    "            img = image[i]\n",
    "            new_scan = (img-np.min(img))/(np.max(img)-np.min(img))\n",
    "            new_image.append(new_scan)\n",
    "        return new_image, label\n",
    "\n",
    "class StackScans(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample\n",
    "        new_image = np.stack(image, axis=-1)\n",
    "        return new_image, label\n",
    "    \n",
    "class BinaryLabel(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample\n",
    "        new_label = np.sign(label)\n",
    "        return image, new_label\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(image), torch.from_numpy(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom data class\n",
    "\n",
    "Flatten each 3D tensor into 2D and stack them into 3D tensors again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset(Dataset):\n",
    "    def __init__(self, image_path = r'./BraTS/BraTS2021_Training_Data', transform=None):\n",
    "        'Initialisation'\n",
    "        self.image_path = image_path\n",
    "        self.folders_name = [folder for folder in os.listdir(self.image_path) if folder != '.DS_Store']\n",
    "        self.images, self.labels = self.get_images()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        if self.transform:\n",
    "            image, label = self.transform(image, label)\n",
    "        return self.images[index], self.labels[index]\n",
    "    \n",
    "    def get_images(self):\n",
    "        images = []\n",
    "        labels = []\n",
    "        for fld_name in self.folders_name:\n",
    "            image = []\n",
    "            for scan_type in ['flair', 't1', 't1ce', 't2']:\n",
    "                path_img = os.path.join(self.image_path, fld_name, fld_name + '_' + scan_type + '.nii.gz')\n",
    "                img = nib.load(path_img).get_fdata()\n",
    "                image.append(img)\n",
    "            \n",
    "            path_label = os.path.join(self.image_path, fld_name, fld_name + '_seg.nii.gz')\n",
    "\n",
    "            label = nib.load(path_label).get_fdata()\n",
    "\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "        images = np.array(images, dtype=np.uint8)\n",
    "        labels = np.array(label, dtype=np.uint8)\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_ind = [[35,215],[10,230]]\n",
    "crop_len = [crop_ind[0][1]-crop_ind[0][0], crop_ind[1][1]-crop_ind[1][0]]\n",
    "scan_depth = 155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BraTSDataset(image_path = r'./BraTS/BraTS2021_Training_Data',\n",
    "                                    transform=transforms.Compose([\n",
    "                                        Crop([[35,215],[10,230]]),\n",
    "                                        Flatten(),\n",
    "                                        ScanNormalize(),\n",
    "                                        StackScans(),\n",
    "                                        BinaryLabel(),\n",
    "                                        ToTensor()\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Marco/.pyenv/versions/3.11.6/lib/python3.11/site-packages/torch/utils/data/dataset.py:414: UserWarning: Length of split at index 1 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(f\"Length of split at index {i} is 0. \"\n",
      "/Users/Marco/.pyenv/versions/3.11.6/lib/python3.11/site-packages/torch/utils/data/dataset.py:414: UserWarning: Length of split at index 2 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(f\"Length of split at index {i} is 0. \"\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_val_test_split = [0.7, 0.2, 0.1]\n",
    "\n",
    "generator = torch.Generator().manual_seed(SEED)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "dataset_indices = list(range(dataset_size))\n",
    "\n",
    "train_sampler, val_sampler, test_sampler = random_split(dataset_indices, train_val_test_split, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                            sampler=train_sampler)\n",
    "validation_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                            sampler=val_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler = test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Input\n",
    "\n",
    "3D Images of size 4 155 180 220 -> 4 180 155 * 220 -> 4 `crop_len[0]` `scan_depth`*`crop_len[1]`\n",
    "\n",
    "Return 155 180 220 -> `scan_depth` `crop_len[0]` `crop_len[1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstCNN(nn.Module):\n",
    "  def __init__(self, output_dim):\n",
    "    super().__init__()\n",
    "\n",
    "    self.features = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=4, out_channels=16, kernel_size=5),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=16, out_channels=64, kernel_size=5),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=64, out_channels=256, kernel_size=5),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    \n",
    "    self.linear = nn.Sequential(\n",
    "      nn.Linear(256 * 5 * 5 * 5, 383625),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(383625, 1534500),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(1534500, output_dim)\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    x = self.linear(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "OUTPUT_DIM = scan_depth * np.prod(crop_len)\n",
    "model = FirstCNN(OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6138000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss() # Softmax + CrossEntropy\n",
    "\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "  '''\n",
    "  Compute accuracy from ground-truth and predicted labels.\n",
    "\n",
    "  Input\n",
    "  ------\n",
    "  y_pred: torch.Tensor [BATCH_SIZE, N_LABELS]\n",
    "  y: torch.Tensor [BATCH_SIZE]\n",
    "\n",
    "  Output\n",
    "  ------\n",
    "  acc: float\n",
    "    Accuracy\n",
    "  '''\n",
    "  y_prob = F.softmax(y_pred, dim = -1)\n",
    "  y_pred = y_prob.argmax(dim=1, keepdim = True)\n",
    "  correct = y_pred.eq(y.view_as(y_pred)).sum()\n",
    "  acc = correct.float()/y.shape[0]\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "\n",
    "  # Train mode\n",
    "  model.train()\n",
    "\n",
    "  for (x,y) in iterator:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    # Set gradients to zero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Make Predictions\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y)\n",
    "\n",
    "    # Compute accuracy\n",
    "    acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # Apply optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Extract data from loss and accuracy\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()\n",
    "\n",
    "  return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "\n",
    "  # Evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Do not compute gradients\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for(x,y) in iterator:\n",
    "\n",
    "      x = x.to(device)\n",
    "      y = y.to(device)\n",
    "\n",
    "      # Make Predictions\n",
    "      y_pred = model(x)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(y_pred, y)\n",
    "\n",
    "      # Compute accuracy\n",
    "      acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "      # Extract data from loss and accuracy\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "\n",
    "  return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(n_epochs, model, train_iterator, valid_iterator, optimizer, criterion, device, model_name='best_model.pt'):\n",
    "\n",
    "  # Initialize validation loss\n",
    "  best_valid_loss = float('inf')\n",
    "\n",
    "  # Save output losses, accs\n",
    "  train_losses = []\n",
    "  train_accs = []\n",
    "  valid_losses = []\n",
    "  valid_accs = []\n",
    "\n",
    "  # Loop over epochs\n",
    "  for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    # Train\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    # Validation\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "    # Save best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "      best_valid_loss = valid_loss\n",
    "      # Save model\n",
    "      torch.save(model.state_dict(), model_name)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"\\nEpoch: {epoch+1}/{n_epochs} -- Epoch Time: {end_time-start_time:.2f} s\")\n",
    "    print(\"---------------------------------\")\n",
    "    print(f\"Train -- Loss: {train_loss:.3f}, Acc: {train_acc * 100:.2f}%\")\n",
    "    print(f\"Val -- Loss: {valid_loss:.3f}, Acc: {valid_acc * 100:.2f}%\")\n",
    "\n",
    "    # Save\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accs.append(valid_acc)\n",
    "\n",
    "  return train_losses, train_accs, valid_losses, valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 30\n",
    "train_losses, train_accs, valid_losses, valid_accs = model_training(N_EPOCHS,\n",
    "                                                                    model,\n",
    "                                                                    train_iterator,\n",
    "                                                                    valid_iterator,\n",
    "                                                                    optimizer,\n",
    "                                                                    criterion,\n",
    "                                                                    device,\n",
    "                                                                    'lenet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(n_epochs, train_losses, train_accs, valid_losses, valid_accs):\n",
    "  N_EPOCHS = n_epochs\n",
    "  # Plot results\n",
    "  plt.figure(figsize=(20, 6))\n",
    "  _ = plt.subplot(1,2,1)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, train_losses, linewidth=3)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, valid_losses, linewidth=3)\n",
    "  _ = plt.legend(['Train', 'Validation'])\n",
    "  plt.grid('on'), plt.xlabel('Epoch'), plt.ylabel('Loss')\n",
    "\n",
    "  _ = plt.subplot(1,2,2)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, train_accs, linewidth=3)\n",
    "  plt.plot(np.arange(N_EPOCHS)+1, valid_accs, linewidth=3)\n",
    "  _ = plt.legend(['Train', 'Validation'])\n",
    "  plt.grid('on'), plt.xlabel('Epoch'), plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing(model, test_iterator, criterion, device, model_name='best_model.pt'):\n",
    "  # Test model\n",
    "  model.load_state_dict(torch.load(model_name))\n",
    "  test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
    "  print(f\"Test -- Loss: {test_loss:.3f}, Acc: {test_acc * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_testing(model, test_loader, criterion, device, 'lenet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, iterator, device):\n",
    "\n",
    "  # Evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  labels = []\n",
    "  pred = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for (x, y) in iterator:\n",
    "      x = x.to(device)\n",
    "      y_pred = model(x)\n",
    "\n",
    "      # Get label with highest score\n",
    "      y_prob = F.softmax(y_pred, dim = -1)\n",
    "      top_pred = y_prob.argmax(1, keepdim=True)\n",
    "\n",
    "      labels.append(y.cpu())\n",
    "      pred.append(top_pred.cpu())\n",
    "\n",
    "  labels = torch.cat(labels, dim=0)\n",
    "  pred = torch.cat(pred, dim=0)\n",
    "\n",
    "  return labels, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(model, test_iterator, device):\n",
    "  labels, pred = predict(model, test_iterator, device)\n",
    "  print(confusion_matrix(labels, pred))\n",
    "  print(\"\\n\")\n",
    "  print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
