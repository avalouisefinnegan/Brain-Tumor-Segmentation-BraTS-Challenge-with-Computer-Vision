{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, time\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch functions\n",
    "import torch\n",
    "# Neural network layers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "# Torchvision library\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# For results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed, use_cuda = True, use_mps = False):\n",
    "    \"\"\"\n",
    "    Set SEED for PyTorch reproducibility\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    if use_mps:\n",
    "        torch.mps.manual_seed(seed)\n",
    "\n",
    "SEED = 44\n",
    "\n",
    "USE_SEED = True\n",
    "\n",
    "if USE_SEED:\n",
    "    set_seed(SEED, torch.cuda.is_available(), torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset_Flair(Dataset):\n",
    "    def __init__(self, image_path = r'./BraTS/BraTS2021_Training_Data_2D', transform=None):\n",
    "        'Initialisation'\n",
    "        self.image_path = image_path\n",
    "        self.folders_name = [folder for folder in os.listdir(self.image_path) if folder != '.DS_Store']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.folders_name) * 155\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Determine the image index and the RGB layer\n",
    "        image_idx = index // 155\n",
    "        layer_idx = index % 155\n",
    "\n",
    "        # Select sample\n",
    "        file_name = self.folders_name[image_idx]\n",
    "        \n",
    "        path_img = os.path.join(self.image_path, file_name, 'flair', file_name + '_flair_' + str(layer_idx+1) + '.npy')\n",
    "        image = np.load(path_img).astype(np.float32)\n",
    "\n",
    "        path_label = os.path.join(self.image_path, file_name, 'seg', file_name + '_seg_' + str(layer_idx+1) + '.npy')\n",
    "        label = np.load(path_label)\n",
    "        \n",
    "        if self.transform:\n",
    "            image, label = self.transform([image, label])\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinariseLabel(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample\n",
    "        new_label = np.sign(label)\n",
    "        return image, new_label\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample\n",
    "\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        # image = image.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(image), torch.from_numpy(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BraTSDataset_Flair(image_path = r'./BraTS/BraTS2021_Training_Data_2D',\n",
    "                                    transform=transforms.Compose([\n",
    "                                        BinariseLabel(),\n",
    "                                        ToTensor()\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = int(len(dataset)/155)\n",
    "dataset_indices = list(range(dataset_size))\n",
    "\n",
    "train_indices, test_indices = train_test_split(dataset_indices, test_size=0.1, random_state=SEED)\n",
    "train_indices, val_indices = train_test_split(train_indices, test_size=0.22, random_state=SEED)\n",
    "\n",
    "tmp_list = [[],[],[]]\n",
    "for i, ind_list in enumerate([train_indices, val_indices, test_indices]):\n",
    "    for ind in ind_list:\n",
    "        for j in range(155):\n",
    "            tmp_list[i].append(ind*155 + j)\n",
    "train_indices, val_indices, test_indices = tmp_list\n",
    "\n",
    "train_subset_Flair = Subset(dataset, train_indices)\n",
    "val_subset_Flair = Subset(dataset, val_indices)\n",
    "test_subset_Flair = Subset(dataset, test_indices)\n",
    "\n",
    "# Create the subset DataLoader\n",
    "train_dataloader_Flair = DataLoader(train_subset_Flair, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader_Flair = DataLoader(val_subset_Flair, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader_Flair = DataLoader(test_subset_Flair, batch_size=batch_size, shuffle=True)\n",
    "# multiprocessing_context=\"forkserver\", persistent_workers=True, num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Convlution Autoencoder Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.features = nn.Sequential(\n",
    "      ## encoder layers ##\n",
    "      # conv layer (depth from 1 --> 4), 3x3 kernels\n",
    "      # Input 64 x 64\n",
    "      nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding = 'same'), # 64 x 64\n",
    "      nn.ReLU(),\n",
    "      # pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "      nn.MaxPool2d(2), ## 32 x 32\n",
    "      # conv layer (depth from 4 --> 8), 4x4 kernels\n",
    "      nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, padding = 'same'), # 32 x 32\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2), # 16 x 16\n",
    "      # conv layer (depth from 8 --> 12), 5x5 kernels\n",
    "      nn.Conv2d(in_channels=8, out_channels=12, kernel_size=3, padding = 'same'), # ( 12 x ) 16 x 16\n",
    "      nn.ReLU(),\n",
    "      \n",
    "      ## decoder layers ##\n",
    "      # add transpose conv layers, with relu activation function\n",
    "      nn.ConvTranspose2d(12, 6, kernel_size = 2, stride=2), # 32 x 32\n",
    "      nn.ReLU(),\n",
    "      nn.ConvTranspose2d(6, 1, kernel_size = 2, stride=2), # 64 x 64\n",
    "      # output layer (with sigmoid for scaling from 0 to 1)\n",
    "      # nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x.view(int(np.prod(x.shape)/(64**2)), 1, 64, 64)\n",
    "    x = self.features(x)\n",
    "    # x = x.view(x.shape[0], -1)\n",
    "    # x = torch.flatten(x, start_dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,531 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "model = ConvAutoencoder().to(device)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and Optimisation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "# criterion = nn.CrossEntropyLoss() # Softmax + CrossEntropy\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 1/50 -- Epoch Time: 171.56 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.696, Acc: 29.58%\n",
      "Val -- Loss: 0.693, Acc: 26.39%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 2/50 -- Epoch Time: 179.73 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 61.51%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 3/50 -- Epoch Time: 178.59 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 4/50 -- Epoch Time: 180.66 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 5/50 -- Epoch Time: 179.01 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 6/50 -- Epoch Time: 178.04 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 7/50 -- Epoch Time: 178.92 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 8/50 -- Epoch Time: 178.38 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 9/50 -- Epoch Time: 177.76 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 10/50 -- Epoch Time: 178.71 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 11/50 -- Epoch Time: 177.70 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 12/50 -- Epoch Time: 178.97 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 13/50 -- Epoch Time: 174.59 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 14/50 -- Epoch Time: 175.22 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 15/50 -- Epoch Time: 179.43 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 16/50 -- Epoch Time: 175.73 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 17/50 -- Epoch Time: 174.61 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 18/50 -- Epoch Time: 173.94 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 19/50 -- Epoch Time: 175.81 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 20/50 -- Epoch Time: 173.79 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 21/50 -- Epoch Time: 174.79 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 22/50 -- Epoch Time: 175.40 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 23/50 -- Epoch Time: 179.98 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 24/50 -- Epoch Time: 179.84 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 25/50 -- Epoch Time: 181.86 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 26/50 -- Epoch Time: 181.14 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 27/50 -- Epoch Time: 179.53 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 28/50 -- Epoch Time: 181.49 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 29/50 -- Epoch Time: 178.87 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 30/50 -- Epoch Time: 176.95 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 31/50 -- Epoch Time: 179.13 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 32/50 -- Epoch Time: 184.37 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 33/50 -- Epoch Time: 181.57 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 34/50 -- Epoch Time: 180.68 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 35/50 -- Epoch Time: 180.67 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 36/50 -- Epoch Time: 182.97 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 37/50 -- Epoch Time: 179.18 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 38/50 -- Epoch Time: 181.20 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 39/50 -- Epoch Time: 181.52 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 40/50 -- Epoch Time: 183.66 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 41/50 -- Epoch Time: 179.49 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 42/50 -- Epoch Time: 181.38 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 43/50 -- Epoch Time: 181.25 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 44/50 -- Epoch Time: 181.09 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 45/50 -- Epoch Time: 180.70 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 46/50 -- Epoch Time: 181.99 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 47/50 -- Epoch Time: 181.37 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 48/50 -- Epoch Time: 181.32 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 49/50 -- Epoch Time: 180.59 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 50/50 -- Epoch Time: 181.65 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n"
     ]
    }
   ],
   "source": [
    "train_losses_Flair, train_accs_Flair, valid_losses_Flair, valid_accs_Flair = model_training(N_EPOCHS,\n",
    "                                                                    model,\n",
    "                                                                    train_dataloader_Flair,\n",
    "                                                                    val_dataloader_Flair,\n",
    "                                                                    optimizer,\n",
    "                                                                    criterion,\n",
    "                                                                    device,\n",
    "                                                                    './models/CA_Flair.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset_T1(Dataset):\n",
    "    def __init__(self, image_path = r'./BraTS/BraTS2021_Training_Data_2D', transform=None):\n",
    "        'Initialisation'\n",
    "        self.image_path = image_path\n",
    "        self.folders_name = [folder for folder in os.listdir(self.image_path) if folder != '.DS_Store']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.folders_name) * 155\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Determine the image index and the RGB layer\n",
    "        image_idx = index // 155\n",
    "        layer_idx = index % 155\n",
    "\n",
    "        # Select sample\n",
    "        file_name = self.folders_name[image_idx]\n",
    "        \n",
    "        path_img = os.path.join(self.image_path, file_name, 't1', file_name + '_t1_' + str(layer_idx+1) + '.npy')\n",
    "        image = np.load(path_img).astype(np.float32)\n",
    "\n",
    "        path_label = os.path.join(self.image_path, file_name, 'seg', file_name + '_seg_' + str(layer_idx+1) + '.npy')\n",
    "        label = np.load(path_label)\n",
    "        \n",
    "        if self.transform:\n",
    "            image, label = self.transform([image, label])\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_T1 = BraTSDataset_T1(image_path = r'./BraTS/BraTS2021_Training_Data_2D',\n",
    "                                    transform=transforms.Compose([\n",
    "                                        BinariseLabel(),\n",
    "                                        ToTensor()\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_T1 = Subset(dataset_T1, train_indices)\n",
    "val_subset_T1 = Subset(dataset_T1, val_indices)\n",
    "test_subset_T1 = Subset(dataset_T1, test_indices)\n",
    "\n",
    "# Create the subset DataLoader\n",
    "train_dataloader_T1 = DataLoader(train_subset_T1, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader_T1 = DataLoader(val_subset_T1, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader_T1 = DataLoader(test_subset_T1, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Model Parameters\n",
    "\n",
    "for layer in model.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 1/50 -- Epoch Time: 213.21 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 2/50 -- Epoch Time: 207.02 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 3/50 -- Epoch Time: 208.49 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 4/50 -- Epoch Time: 207.48 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 5/50 -- Epoch Time: 208.15 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 6/50 -- Epoch Time: 207.52 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 7/50 -- Epoch Time: 205.34 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 8/50 -- Epoch Time: 207.48 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 9/50 -- Epoch Time: 205.35 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 10/50 -- Epoch Time: 206.30 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 11/50 -- Epoch Time: 206.25 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 12/50 -- Epoch Time: 207.09 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 13/50 -- Epoch Time: 215.08 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 14/50 -- Epoch Time: 203.57 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 15/50 -- Epoch Time: 202.19 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 16/50 -- Epoch Time: 199.59 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 17/50 -- Epoch Time: 200.05 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 18/50 -- Epoch Time: 199.26 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 19/50 -- Epoch Time: 201.18 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 20/50 -- Epoch Time: 200.93 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 21/50 -- Epoch Time: 202.37 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 22/50 -- Epoch Time: 203.00 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 23/50 -- Epoch Time: 201.15 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 24/50 -- Epoch Time: 202.38 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 25/50 -- Epoch Time: 200.33 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 26/50 -- Epoch Time: 200.25 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 27/50 -- Epoch Time: 200.49 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 28/50 -- Epoch Time: 202.57 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 29/50 -- Epoch Time: 199.50 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 30/50 -- Epoch Time: 200.72 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 31/50 -- Epoch Time: 201.41 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 32/50 -- Epoch Time: 201.36 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 33/50 -- Epoch Time: 201.19 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 34/50 -- Epoch Time: 203.47 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 35/50 -- Epoch Time: 203.99 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 36/50 -- Epoch Time: 204.16 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 37/50 -- Epoch Time: 204.21 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 38/50 -- Epoch Time: 205.06 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 39/50 -- Epoch Time: 204.21 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 40/50 -- Epoch Time: 203.32 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 41/50 -- Epoch Time: 204.54 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 42/50 -- Epoch Time: 206.93 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 43/50 -- Epoch Time: 203.49 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 44/50 -- Epoch Time: 204.03 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 45/50 -- Epoch Time: 204.26 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 46/50 -- Epoch Time: 203.35 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 47/50 -- Epoch Time: 203.85 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 48/50 -- Epoch Time: 206.93 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 49/50 -- Epoch Time: 206.73 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 50/50 -- Epoch Time: 207.45 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n"
     ]
    }
   ],
   "source": [
    "train_losses_T1, train_accs_T1, valid_losses_T1, valid_accs_T1 = model_training(N_EPOCHS,\n",
    "                                                                    model,\n",
    "                                                                    train_dataloader_T1,\n",
    "                                                                    val_dataloader_T1,\n",
    "                                                                    optimizer,\n",
    "                                                                    criterion,\n",
    "                                                                    device,\n",
    "                                                                    './models/CA_T1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset_T1CE(Dataset):\n",
    "    def __init__(self, image_path = r'./BraTS/BraTS2021_Training_Data_2D', transform=None):\n",
    "        'Initialisation'\n",
    "        self.image_path = image_path\n",
    "        self.folders_name = [folder for folder in os.listdir(self.image_path) if folder != '.DS_Store']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.folders_name) * 155\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Determine the image index and the RGB layer\n",
    "        image_idx = index // 155\n",
    "        layer_idx = index % 155\n",
    "\n",
    "        # Select sample\n",
    "        file_name = self.folders_name[image_idx]\n",
    "        \n",
    "        path_img = os.path.join(self.image_path, file_name, 't1', file_name + '_t1_' + str(layer_idx+1) + '.npy')\n",
    "        image = np.load(path_img).astype(np.float32)\n",
    "\n",
    "        path_label = os.path.join(self.image_path, file_name, 'seg', file_name + '_seg_' + str(layer_idx+1) + '.npy')\n",
    "        label = np.load(path_label)\n",
    "        \n",
    "        if self.transform:\n",
    "            image, label = self.transform([image, label])\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_T1CE = BraTSDataset_T1CE(image_path = r'./BraTS/BraTS2021_Training_Data_2D',\n",
    "                                    transform=transforms.Compose([\n",
    "                                        BinariseLabel(),\n",
    "                                        ToTensor()\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_T1CE = Subset(dataset_T1CE, train_indices)\n",
    "val_subset_T1CE = Subset(dataset_T1CE, val_indices)\n",
    "test_subset_T1CE = Subset(dataset_T1CE, test_indices)\n",
    "\n",
    "# Create the subset DataLoader\n",
    "train_dataloader_T1CE = DataLoader(train_subset_T1CE, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader_T1CE = DataLoader(val_subset_T1CE, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader_T1CE = DataLoader(test_subset_T1CE, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Model Parameters\n",
    "\n",
    "for layer in model.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 1/50 -- Epoch Time: 207.35 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 2/50 -- Epoch Time: 203.97 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 3/50 -- Epoch Time: 204.87 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 4/50 -- Epoch Time: 204.01 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 5/50 -- Epoch Time: 204.13 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 6/50 -- Epoch Time: 206.05 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 7/50 -- Epoch Time: 204.61 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 8/50 -- Epoch Time: 205.11 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 9/50 -- Epoch Time: 204.10 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 10/50 -- Epoch Time: 205.22 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 11/50 -- Epoch Time: 203.26 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 12/50 -- Epoch Time: 206.20 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 13/50 -- Epoch Time: 204.23 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 14/50 -- Epoch Time: 203.04 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 15/50 -- Epoch Time: 205.50 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 16/50 -- Epoch Time: 205.41 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 17/50 -- Epoch Time: 203.25 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 18/50 -- Epoch Time: 204.49 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 19/50 -- Epoch Time: 204.06 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 20/50 -- Epoch Time: 204.31 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 21/50 -- Epoch Time: 204.00 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 22/50 -- Epoch Time: 206.19 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 23/50 -- Epoch Time: 204.75 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 24/50 -- Epoch Time: 203.06 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 25/50 -- Epoch Time: 204.05 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 26/50 -- Epoch Time: 203.75 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 27/50 -- Epoch Time: 205.58 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 28/50 -- Epoch Time: 203.09 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 29/50 -- Epoch Time: 204.79 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 30/50 -- Epoch Time: 206.43 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 31/50 -- Epoch Time: 203.45 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 32/50 -- Epoch Time: 202.95 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 33/50 -- Epoch Time: 204.91 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 34/50 -- Epoch Time: 207.19 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 35/50 -- Epoch Time: 206.99 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 36/50 -- Epoch Time: 202.99 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 37/50 -- Epoch Time: 204.90 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 38/50 -- Epoch Time: 206.44 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 39/50 -- Epoch Time: 204.44 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 40/50 -- Epoch Time: 204.45 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 41/50 -- Epoch Time: 204.32 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 42/50 -- Epoch Time: 204.00 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 43/50 -- Epoch Time: 204.72 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 44/50 -- Epoch Time: 204.46 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 45/50 -- Epoch Time: 206.76 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 46/50 -- Epoch Time: 205.90 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 47/50 -- Epoch Time: 204.06 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 48/50 -- Epoch Time: 203.75 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 49/50 -- Epoch Time: 203.23 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 50/50 -- Epoch Time: 205.22 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n"
     ]
    }
   ],
   "source": [
    "train_losses_T1CE, train_accs_T1CE, valid_losses_T1CE, valid_accs_T1CE = model_training(N_EPOCHS,\n",
    "                                                                    model,\n",
    "                                                                    train_dataloader_T1CE,\n",
    "                                                                    val_dataloader_T1CE,\n",
    "                                                                    optimizer,\n",
    "                                                                    criterion,\n",
    "                                                                    device,\n",
    "                                                                    './models/CA_T1CE.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset_T2(Dataset):\n",
    "    def __init__(self, image_path = r'./BraTS/BraTS2021_Training_Data_2D', transform=None):\n",
    "        'Initialisation'\n",
    "        self.image_path = image_path\n",
    "        self.folders_name = [folder for folder in os.listdir(self.image_path) if folder != '.DS_Store']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.folders_name) * 155\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Determine the image index and the RGB layer\n",
    "        image_idx = index // 155\n",
    "        layer_idx = index % 155\n",
    "\n",
    "        # Select sample\n",
    "        file_name = self.folders_name[image_idx]\n",
    "        \n",
    "        path_img = os.path.join(self.image_path, file_name, 't1', file_name + '_t1_' + str(layer_idx+1) + '.npy')\n",
    "        image = np.load(path_img).astype(np.float32)\n",
    "\n",
    "        path_label = os.path.join(self.image_path, file_name, 'seg', file_name + '_seg_' + str(layer_idx+1) + '.npy')\n",
    "        label = np.load(path_label)\n",
    "        \n",
    "        if self.transform:\n",
    "            image, label = self.transform([image, label])\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_T2 = BraTSDataset_T2(image_path = r'./BraTS/BraTS2021_Training_Data_2D',\n",
    "                                    transform=transforms.Compose([\n",
    "                                        BinariseLabel(),\n",
    "                                        ToTensor()\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_T2 = Subset(dataset_T2, train_indices)\n",
    "val_subset_T2 = Subset(dataset_T2, val_indices)\n",
    "test_subset_T2 = Subset(dataset_T2, test_indices)\n",
    "\n",
    "# Create the subset DataLoader\n",
    "train_dataloader_T2 = DataLoader(train_subset_T2, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader_T2 = DataLoader(val_subset_T2, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader_T2 = DataLoader(test_subset_T2, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Model Parameters\n",
    "\n",
    "for layer in model.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 1/50 -- Epoch Time: 203.63 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 2/50 -- Epoch Time: 204.72 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 3/50 -- Epoch Time: 202.99 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 4/50 -- Epoch Time: 205.03 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 5/50 -- Epoch Time: 206.05 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 6/50 -- Epoch Time: 204.00 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 7/50 -- Epoch Time: 203.42 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 8/50 -- Epoch Time: 202.46 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 9/50 -- Epoch Time: 201.04 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 10/50 -- Epoch Time: 202.01 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 11/50 -- Epoch Time: 202.47 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 12/50 -- Epoch Time: 201.58 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 13/50 -- Epoch Time: 201.81 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 14/50 -- Epoch Time: 203.51 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 15/50 -- Epoch Time: 202.78 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 16/50 -- Epoch Time: 201.85 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 17/50 -- Epoch Time: 201.23 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 18/50 -- Epoch Time: 202.54 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 19/50 -- Epoch Time: 202.89 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 20/50 -- Epoch Time: 201.80 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 21/50 -- Epoch Time: 201.85 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 22/50 -- Epoch Time: 200.81 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 23/50 -- Epoch Time: 202.81 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 24/50 -- Epoch Time: 203.53 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 25/50 -- Epoch Time: 202.73 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 26/50 -- Epoch Time: 202.49 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 27/50 -- Epoch Time: 202.29 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 28/50 -- Epoch Time: 202.75 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 29/50 -- Epoch Time: 202.47 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 30/50 -- Epoch Time: 201.80 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 31/50 -- Epoch Time: 204.45 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 32/50 -- Epoch Time: 202.72 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 33/50 -- Epoch Time: 198.01 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 34/50 -- Epoch Time: 195.02 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 35/50 -- Epoch Time: 194.83 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 36/50 -- Epoch Time: 197.42 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 37/50 -- Epoch Time: 195.86 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 38/50 -- Epoch Time: 192.92 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 39/50 -- Epoch Time: 193.60 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 40/50 -- Epoch Time: 193.10 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 41/50 -- Epoch Time: 196.62 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 42/50 -- Epoch Time: 193.11 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 43/50 -- Epoch Time: 204.27 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 44/50 -- Epoch Time: 201.20 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 45/50 -- Epoch Time: 199.93 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 46/50 -- Epoch Time: 199.98 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 47/50 -- Epoch Time: 198.33 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 48/50 -- Epoch Time: 199.16 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 49/50 -- Epoch Time: 198.09 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n",
      "100.0 % loaded in this epoch for evaluation.\n",
      "Epoch: 50/50 -- Epoch Time: 199.18 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.693, Acc: 97.33%\n",
      "Val -- Loss: 0.693, Acc: 97.22%\n"
     ]
    }
   ],
   "source": [
    "train_losses_T2, train_accs_T2, valid_losses_T2, valid_accs_T2 = model_training(N_EPOCHS,\n",
    "                                                                    model,\n",
    "                                                                    train_dataloader_T2,\n",
    "                                                                    val_dataloader_T2,\n",
    "                                                                    optimizer,\n",
    "                                                                    criterion,\n",
    "                                                                    device,\n",
    "                                                                    './models/CA_T2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save train, val and test indices, losses and accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses, train_accs, valid_losses, valid_accs\n",
    "# train_losses_T1, train_accs_T1, valid_losses_T1, valid_accs_T1\n",
    "# train_losses_T1CE, train_accs_T1CE, valid_losses_T1CE, valid_accs_T1CE\n",
    "# train_losses_T2, train_accs_T2, valid_losses_T2, valid_accs_T2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
