{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectron2 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install = False\n",
    "\n",
    "if install:\n",
    "    !pip3 install torch torchvision torchaudio --upgrade\n",
    "    !CC=clang CXX=clang++ ARCHFLAGS=\"-arch arm64\" python3 -m pip install 'git+https://github.com/facebookresearch/detectron2.git' --no-build-isolation\n",
    "    !pip3 install wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\n",
      "torch:  2.2 ; cuda:  2.2.2\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "- Convert nii.gz files to 2D png files (Flair only for this model) with `3D to 2D.ipynb`\n",
    "- Convert masked segmentation images to COCO JSON format (required format for Detectron2), see [image-to-coco-json-converter](https://github.com/chrise96/image-to-coco-json-converter) and [binary-to-coco-json-converter](https://github.com/brunobelloni/binary-to-coco-json-converter/). For every segmentation file, save each type of tumor in a separate png file with white pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json, os, cv2\n",
    "\n",
    "image_id = 0\n",
    "\n",
    "def find_contours(sub_mask):\n",
    "    gray = cv2.cvtColor(sub_mask, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "\n",
    "def create_category_annotation(category_dict):\n",
    "    category_list = []\n",
    "    for key, value in category_dict.items():\n",
    "        category = {\"id\": value, \"name\": key, \"supercategory\": key}\n",
    "        category_list.append(category)\n",
    "    return category_list\n",
    "\n",
    "\n",
    "def create_image_annotation(file_name, width, height):\n",
    "    global image_id\n",
    "    image_id += 1\n",
    "    return {\n",
    "        \"id\": image_id,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"file_name\": file_name,\n",
    "    }\n",
    "\n",
    "\n",
    "def create_annotation_format(contour, image_id_, category_id, annotation_id):\n",
    "    return {\n",
    "        \"iscrowd\": 0,\n",
    "        \"id\": annotation_id,\n",
    "        \"image_id\": image_id_,\n",
    "        \"category_id\": category_id,\n",
    "        \"bbox\": cv2.boundingRect(contour),\n",
    "        \"area\": cv2.contourArea(contour),\n",
    "        \"segmentation\": [contour.flatten().tolist()],\n",
    "    }\n",
    "\n",
    "\n",
    "def get_coco_json_format():\n",
    "    return {\n",
    "        \"info\": {},\n",
    "        \"licenses\": [],\n",
    "        \"images\": [{}],\n",
    "        \"categories\": [{}],\n",
    "        \"annotations\": [{}],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label ids of the dataset\n",
    "category_ids = {\n",
    "    'NCR': 1,\n",
    "    'ED' : 2,\n",
    "    \"ET\" : 4,\n",
    "}\n",
    "\n",
    "MASK_EXT = 'png'\n",
    "ORIGINAL_EXT = 'png'\n",
    "\n",
    "\n",
    "# Get \"images\" and \"annotations\" info\n",
    "def images_annotations_info(maskpath):\n",
    "    annotation_id = 0\n",
    "    annotations = []\n",
    "    images = []\n",
    "\n",
    "    for category in category_ids.keys():\n",
    "        for mask_image in glob.glob(os.path.join(maskpath, category, f'*.{MASK_EXT}')):\n",
    "            original_file_name = f'{os.path.basename(mask_image).split(\".\")[0]}.{ORIGINAL_EXT}'\n",
    "            mask_image_open = cv2.imread(mask_image)\n",
    "            height, width, c = mask_image_open.shape\n",
    "\n",
    "            if original_file_name not in map(lambda img: img['file_name'], images):\n",
    "                image = create_image_annotation(file_name=original_file_name, width=width, height=height)\n",
    "                images.append(image)\n",
    "            else:\n",
    "                image = [element for element in images if element['file_name'] == original_file_name][0]\n",
    "\n",
    "            contours = find_contours(mask_image_open)\n",
    "\n",
    "            for contour in contours:\n",
    "                annotation = create_annotation_format(contour, image['id'], category_ids[category], annotation_id)\n",
    "                if annotation['area'] > 0:\n",
    "                    annotations.append(annotation)\n",
    "                    annotation_id += 1\n",
    "\n",
    "    return images, annotations, annotation_id\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    coco_format = get_coco_json_format()  # Get the standard COCO JSON format\n",
    "\n",
    "    mask_path = 'BraTS2021_Training_Data_array/'\n",
    "\n",
    "    for keyword in [\"valid\", \"test\", \"train\"]:\n",
    "        mask_path = f\"BraTS2021_Testing_Data_array/{keyword}_mask/\"\n",
    "        # mask_path = f\"BraTS2021_Training_Data_array/{keyword}_mask/\"\n",
    "\n",
    "        # Create category section\n",
    "        coco_format[\"categories\"] = create_category_annotation(category_ids)\n",
    "\n",
    "        # Create images and annotations sections\n",
    "        coco_format[\"images\"], coco_format[\"annotations\"], annotation_cnt = images_annotations_info(mask_path)\n",
    "\n",
    "        with open(f\"output/{keyword}.json\", \"w\") as outfile:\n",
    "            json.dump(coco_format, outfile, sort_keys=True, indent=4)\n",
    "\n",
    "        print(\"Created %d annotations for images in folder: %s\" % (annotation_cnt, mask_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
